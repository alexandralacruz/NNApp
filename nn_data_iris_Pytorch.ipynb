{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##ANN - Pytorch\n",
        "\n",
        "by Alexandra La Cruz\n"
      ],
      "metadata": {
        "id": "txFglFLdp81L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC8gpkPHpUEh",
        "outputId": "b8865a3b-2edf-42c4-d35c-bb7afc092145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from skorch) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.16.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
            "Downloading skorch-1.2.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skorch\n",
            "Successfully installed skorch-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyyasCO3juAa",
        "outputId": "60494f17-c4ce-4b40-817f-e0d975a5c6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500], Loss: 1.2453\n",
            "Epoch [20/500], Loss: 1.1971\n",
            "Epoch [30/500], Loss: 1.2260\n",
            "Epoch [40/500], Loss: 1.1904\n",
            "Epoch [50/500], Loss: 1.0514\n",
            "Epoch [60/500], Loss: 0.9504\n",
            "Epoch [70/500], Loss: 0.9320\n",
            "Epoch [80/500], Loss: 0.8506\n",
            "Epoch [90/500], Loss: 0.7809\n",
            "Epoch [100/500], Loss: 0.8170\n",
            "Epoch [110/500], Loss: 0.6320\n",
            "Epoch [120/500], Loss: 0.6913\n",
            "Epoch [130/500], Loss: 0.6341\n",
            "Epoch [140/500], Loss: 0.6306\n",
            "Epoch [150/500], Loss: 0.5480\n",
            "Epoch [160/500], Loss: 0.6018\n",
            "Epoch [170/500], Loss: 0.6582\n",
            "Epoch [180/500], Loss: 0.5317\n",
            "Epoch [190/500], Loss: 0.5151\n",
            "Epoch [200/500], Loss: 0.5325\n",
            "Epoch [210/500], Loss: 0.5714\n",
            "Epoch [220/500], Loss: 0.5700\n",
            "Epoch [230/500], Loss: 0.5999\n",
            "Epoch [240/500], Loss: 0.4531\n",
            "Epoch [250/500], Loss: 0.4987\n",
            "Epoch [260/500], Loss: 0.5014\n",
            "Epoch [270/500], Loss: 0.4684\n",
            "Epoch [280/500], Loss: 0.3882\n",
            "Epoch [290/500], Loss: 0.4301\n",
            "Epoch [300/500], Loss: 0.4565\n",
            "Epoch [310/500], Loss: 0.4596\n",
            "Epoch [320/500], Loss: 0.3956\n",
            "Epoch [330/500], Loss: 0.4480\n",
            "Epoch [340/500], Loss: 0.4164\n",
            "Epoch [350/500], Loss: 0.3353\n",
            "Epoch [360/500], Loss: 0.4656\n",
            "Epoch [370/500], Loss: 0.4135\n",
            "Epoch [380/500], Loss: 0.4204\n",
            "Epoch [390/500], Loss: 0.4075\n",
            "Epoch [400/500], Loss: 0.3827\n",
            "Epoch [410/500], Loss: 0.3630\n",
            "Epoch [420/500], Loss: 0.3458\n",
            "Epoch [430/500], Loss: 0.3677\n",
            "Epoch [440/500], Loss: 0.2916\n",
            "Epoch [450/500], Loss: 0.3162\n",
            "Epoch [460/500], Loss: 0.3610\n",
            "Epoch [470/500], Loss: 0.3101\n",
            "Epoch [480/500], Loss: 0.2720\n",
            "Epoch [490/500], Loss: 0.2706\n",
            "Epoch [500/500], Loss: 0.3160\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar los datos / Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convertir a tensores de PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Usar torch.long para clasificación multiclase y torch.float32 para clasificación multi-label\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)   # Usar torch.long para clasificación multiclase  y torch.float32 para clasificación multi-label\n",
        "\n",
        "# Crear DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Instanciar el modelo\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))  # Obtener el número de clases únicas\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, num_classes))\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss para clasificación multiclase y nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Obtener las clases predichas\n",
        "    accuracy = (predicted == y_test_tensor).float().mean()\n",
        "    print(classification_report(y_test_tensor, predicted))\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y, predictions))\n",
        "#"
      ],
      "metadata": {
        "id": "E-z335u-94Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "U58Whprf0l1Z",
        "outputId": "f5533f3e-b3d6-4134-9e0f-a1475f563088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Función para crear el modelo\n",
        "def create_model(input_size, hidden_sizes, num_classes):\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
        "    layers.append(nn.ReLU())\n",
        "    for i in range(len(hidden_sizes) - 1):\n",
        "        layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Función para entrenar y evaluar el modelo\n",
        "def train_and_evaluate(model, train_loader, val_loader, epochs=100, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "arjDscfjmRPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de validación cruzada\n",
        "def cross_validate(X_tensor, y_tensor, hidden_sizes_list, epochs=100, lr=0.001, k=5):\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = {}\n",
        "\n",
        "    for hidden_sizes in hidden_sizes_list:\n",
        "        accuracies = []\n",
        "        for train_index, val_index in skf.split(X_tensor, y_tensor):\n",
        "            X_train, X_val = X_tensor[train_index], X_tensor[val_index]\n",
        "            y_train, y_val = y_tensor[train_index], y_tensor[val_index]\n",
        "\n",
        "            train_dataset = TensorDataset(X_train, y_train)\n",
        "            val_dataset = TensorDataset(X_val, y_val)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "            model = create_model(X_tensor.shape[1], hidden_sizes, len(np.unique(y)))\n",
        "            accuracy = train_and_evaluate(model, train_loader, val_loader, epochs, lr)\n",
        "            accuracies.append(accuracy)\n",
        "        results[str(hidden_sizes)] = np.mean(accuracies)\n",
        "    return results"
      ],
      "metadata": {
        "id": "viZhOmQgmVxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las arquitecturas a probar\n",
        "hidden_sizes_list = [\n",
        "    [8,4],  # 2 capa, 8 y 4 neuronas\n",
        "    [20, 10], # 2 capas, 10 y 8 neuronas\n",
        "    [30, 20, 10], # 3 capas, 30,20 y 10 neuronas\n",
        "    [64,32], # 2 capas, 64 y 32 neuronas\n",
        "]\n",
        "\n",
        "# Ejecutar la validación cruzada\n",
        "results = cross_validate(X_train_tensor, y_train_tensor, hidden_sizes_list)\n",
        "\n",
        "# Imprimir los resultados\n",
        "for architecture, accuracy in results.items():\n",
        "    print(f\"Arquitectura: {architecture}, Precisión promedio: {accuracy:.4f}\")\n",
        "\n",
        "# Encontrar la mejor arquitectura\n",
        "best_architecture = max(results, key=results.get)\n",
        "best_accuracy = results[best_architecture]\n",
        "print(f\"\\nMejor arquitectura: {best_architecture}, Mejor precisión promedio: {best_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVlinh9TmYq8",
        "outputId": "c4255429-83e6-4227-aa9d-0ed6db1f7125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura: [8, 4], Precisión promedio: 0.9167\n",
            "Arquitectura: [20, 10], Precisión promedio: 0.9417\n",
            "Arquitectura: [30, 20, 10], Precisión promedio: 0.9250\n",
            "Arquitectura: [64, 32], Precisión promedio: 0.9250\n",
            "\n",
            "Mejor arquitectura: [20, 10], Mejor precisión promedio: 0.9417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(best_architecture)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF739locoIH2",
        "outputId": "4de5d505-c1ff-4b0f-9446-e73b1dbe3afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(X_test.shape[1], eval(best_architecture), len(np.unique(y)))\n",
        "\n",
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Obtener las clases predichas\n",
        "    accuracy = (predicted == y_test_tensor).float().mean()\n",
        "    print(f'Test Accuracy: {accuracy.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVIWOv6kns95",
        "outputId": "8d44a302-54f4-4367-9b86-a1cc9fe902be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.3667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYGMN8zptiv4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}