{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txFglFLdp81L"
      },
      "source": [
        "##ANN - Pytorch\n",
        "\n",
        "by Alexandra La Cruz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save ONLY the validation features to CSV (no target)\n",
        "X_val_df = pd.DataFrame(X_val, columns=iris.feature_names)\n",
        "X_df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "X_df[\"target\"] = y          # add the label as a new column\n",
        "\n",
        "\n",
        "# Guardar a CSV sin la columna índice\n",
        "X_val_df.to_csv(\"../datasets/tabular/iris_topredict.csv\", index=False)\n",
        "X_df.to_csv(\"../datasets/tabular/iris_totrain.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyyasCO3juAa",
        "outputId": "60494f17-c4ce-4b40-817f-e0d975a5c6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/500], Loss: 1.1701\n",
            "Epoch [20/500], Loss: 1.1932\n",
            "Epoch [30/500], Loss: 1.1417\n",
            "Epoch [40/500], Loss: 1.0706\n",
            "Epoch [50/500], Loss: 1.1012\n",
            "Epoch [60/500], Loss: 1.1499\n",
            "Epoch [70/500], Loss: 1.0792\n",
            "Epoch [80/500], Loss: 1.0692\n",
            "Epoch [90/500], Loss: 1.0999\n",
            "Epoch [100/500], Loss: 1.0267\n",
            "Epoch [110/500], Loss: 1.0617\n",
            "Epoch [120/500], Loss: 0.9818\n",
            "Epoch [130/500], Loss: 0.9670\n",
            "Epoch [140/500], Loss: 1.0418\n",
            "Epoch [150/500], Loss: 0.9320\n",
            "Epoch [160/500], Loss: 0.9755\n",
            "Epoch [170/500], Loss: 1.0059\n",
            "Epoch [180/500], Loss: 0.9704\n",
            "Epoch [190/500], Loss: 0.8279\n",
            "Epoch [200/500], Loss: 0.8825\n",
            "Epoch [210/500], Loss: 0.8470\n",
            "Epoch [220/500], Loss: 0.9312\n",
            "Epoch [230/500], Loss: 0.8251\n",
            "Epoch [240/500], Loss: 0.7740\n",
            "Epoch [250/500], Loss: 0.8993\n",
            "Epoch [260/500], Loss: 0.7619\n",
            "Epoch [270/500], Loss: 0.8676\n",
            "Epoch [280/500], Loss: 0.7758\n",
            "Epoch [290/500], Loss: 0.7284\n",
            "Epoch [300/500], Loss: 0.7323\n",
            "Epoch [310/500], Loss: 0.6947\n",
            "Epoch [320/500], Loss: 0.6703\n",
            "Epoch [330/500], Loss: 0.7269\n",
            "Epoch [340/500], Loss: 0.6771\n",
            "Epoch [350/500], Loss: 0.6716\n",
            "Epoch [360/500], Loss: 0.6957\n",
            "Epoch [370/500], Loss: 0.6460\n",
            "Epoch [380/500], Loss: 0.6310\n",
            "Epoch [390/500], Loss: 0.6142\n",
            "Epoch [400/500], Loss: 0.6318\n",
            "Epoch [410/500], Loss: 0.5510\n",
            "Epoch [420/500], Loss: 0.6222\n",
            "Epoch [430/500], Loss: 0.5646\n",
            "Epoch [440/500], Loss: 0.5570\n",
            "Epoch [450/500], Loss: 0.5787\n",
            "Epoch [460/500], Loss: 0.5035\n",
            "Epoch [470/500], Loss: 0.5665\n",
            "Epoch [480/500], Loss: 0.5811\n",
            "Epoch [490/500], Loss: 0.5206\n",
            "Epoch [500/500], Loss: 0.5722\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.69      1.00      0.82         9\n",
            "           2       1.00      0.64      0.78        11\n",
            "\n",
            "    accuracy                           0.87        30\n",
            "   macro avg       0.90      0.88      0.87        30\n",
            "weighted avg       0.91      0.87      0.86        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Escalar los datos / Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convertir a tensores de PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Usar torch.long para clasificación multiclase y torch.float32 para clasificación multi-label\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)   # Usar torch.long para clasificación multiclase  y torch.float32 para clasificación multi-label\n",
        "\n",
        "# Crear DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Instanciar el modelo\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))  # Obtener el número de clases únicas\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, 4),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, num_classes))\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss para clasificación multiclase y nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Obtener las clases predichas\n",
        "    accuracy = (predicted == y_test_tensor).float().mean()\n",
        "    print(classification_report(y_test_tensor, predicted))\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E-z335u-94Nn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_tensor, predicted))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U58Whprf0l1Z",
        "outputId": "f5533f3e-b3d6-4134-9e0f-a1475f563088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "arjDscfjmRPC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Función para crear el modelo\n",
        "def create_model(input_size, hidden_sizes, num_classes):\n",
        "    layers = []\n",
        "    layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
        "    layers.append(nn.ReLU())\n",
        "    for i in range(len(hidden_sizes) - 1):\n",
        "        layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Función para entrenar y evaluar el modelo\n",
        "def train_and_evaluate(model, train_loader, val_loader, epochs=100, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "viZhOmQgmVxQ"
      },
      "outputs": [],
      "source": [
        "# Función de validación cruzada\n",
        "def cross_validate(X_tensor, y_tensor, hidden_sizes_list, epochs=100, lr=0.001, k=5):\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = {}\n",
        "\n",
        "    for hidden_sizes in hidden_sizes_list:\n",
        "        accuracies = []\n",
        "        for train_index, val_index in skf.split(X_tensor, y_tensor):\n",
        "            X_train, X_val = X_tensor[train_index], X_tensor[val_index]\n",
        "            y_train, y_val = y_tensor[train_index], y_tensor[val_index]\n",
        "\n",
        "            train_dataset = TensorDataset(X_train, y_train)\n",
        "            val_dataset = TensorDataset(X_val, y_val)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "            model = create_model(X_tensor.shape[1], hidden_sizes, len(np.unique(y)))\n",
        "            accuracy = train_and_evaluate(model, train_loader, val_loader, epochs, lr)\n",
        "            accuracies.append(accuracy)\n",
        "        results[str(hidden_sizes)] = np.mean(accuracies)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVlinh9TmYq8",
        "outputId": "c4255429-83e6-4227-aa9d-0ed6db1f7125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquitectura: [8, 4], Precisión promedio: 0.9467\n",
            "Arquitectura: [20, 10], Precisión promedio: 0.9789\n",
            "Arquitectura: [30, 20, 10], Precisión promedio: 0.9678\n",
            "Arquitectura: [64, 32], Precisión promedio: 0.9567\n",
            "\n",
            "Mejor arquitectura: [20, 10], Mejor precisión promedio: 0.9789\n"
          ]
        }
      ],
      "source": [
        "# Definir las arquitecturas a probar\n",
        "hidden_sizes_list = [\n",
        "    [8,4],  # 2 capa, 8 y 4 neuronas\n",
        "    [20, 10], # 2 capas, 10 y 8 neuronas\n",
        "    [30, 20, 10], # 3 capas, 30,20 y 10 neuronas\n",
        "    [64,32], # 2 capas, 64 y 32 neuronas\n",
        "]\n",
        "\n",
        "# Ejecutar la validación cruzada\n",
        "results = cross_validate(X_train_tensor, y_train_tensor, hidden_sizes_list, epochs=200, lr=0.001, k=10)\n",
        "\n",
        "# Imprimir los resultados\n",
        "for architecture, accuracy in results.items():\n",
        "    print(f\"Arquitectura: {architecture}, Precisión promedio: {accuracy:.4f}\")\n",
        "\n",
        "# Encontrar la mejor arquitectura\n",
        "best_architecture = max(results, key=results.get)\n",
        "best_accuracy = results[best_architecture]\n",
        "print(f\"\\nMejor arquitectura: {best_architecture}, Mejor precisión promedio: {best_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF739locoIH2",
        "outputId": "4de5d505-c1ff-4b0f-9446-e73b1dbe3afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[20, 10]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval(best_architecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVIWOv6kns95",
        "outputId": "8d44a302-54f4-4367-9b86-a1cc9fe902be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4667\n"
          ]
        }
      ],
      "source": [
        "model = create_model(X_test.shape[1], eval(best_architecture), len(np.unique(y)))\n",
        "\n",
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Obtener las clases predichas\n",
        "    accuracy = (predicted == y_test_tensor).float().mean()\n",
        "    print(f'Test Accuracy: {accuracy.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGMN8zptiv4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
