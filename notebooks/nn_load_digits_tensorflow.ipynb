{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1R0uutltS3X",
        "outputId": "91eb47e7-a7c3-450a-99ec-2bac6c223cbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USUARIO\\Downloads\\ANN TensorFlow And Pytorch\\NNapp1\\NNapp\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4398 - loss: 1.8745\n",
            "Epoch 2/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.9580\n",
            "Epoch 3/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.4846\n",
            "Epoch 4/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.2762\n",
            "Epoch 5/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1804\n",
            "Epoch 6/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1294\n",
            "Epoch 7/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0979\n",
            "Epoch 8/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0768\n",
            "Epoch 9/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0607\n",
            "Epoch 10/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0499\n",
            "Epoch 11/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0398\n",
            "Epoch 12/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0330\n",
            "Epoch 13/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0273\n",
            "Epoch 14/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0229\n",
            "Epoch 15/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0194\n",
            "Epoch 16/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0166\n",
            "Epoch 17/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0146\n",
            "Epoch 18/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0125\n",
            "Epoch 19/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0109\n",
            "Epoch 20/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0096\n",
            "Epoch 21/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 22/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0077\n",
            "Epoch 23/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069\n",
            "Epoch 24/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0062\n",
            "Epoch 25/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0056\n",
            "Epoch 26/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 27/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0046\n",
            "Epoch 28/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042\n",
            "Epoch 29/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 30/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 31/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 32/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 33/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 34/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 35/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 36/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 37/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 38/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 39/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 40/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018    \n",
            "Epoch 41/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 42/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 43/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 44/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
            "Epoch 45/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 46/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 47/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
            "Epoch 48/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 49/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 50/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.0802  \n",
            "\n",
            "Test Accuracy: 0.9694\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      0.96      0.98        28\n",
            "           2       0.94      0.97      0.96        33\n",
            "           3       0.91      0.94      0.93        34\n",
            "           4       1.00      1.00      1.00        46\n",
            "           5       0.94      0.96      0.95        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       1.00      0.97      0.98        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el dataset de dígitos (8x8 imágenes)\n",
        "digits = load_digits()\n",
        "X, y = digits.images, digits.target  # X tiene forma (n_samples, 8, 8)\n",
        "\n",
        "# Aplanar las imágenes para redes densas (Fully Connected)\n",
        "X = X.reshape(X.shape[0], -1)  # de (n_samples, 8, 8) a (n_samples, 64)\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Número de clases\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Definir el modelo\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes)  # Logits\n",
        "])\n",
        "\n",
        "# Compilar\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluar\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'\\nTest Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Predicciones\n",
        "logits = model.predict(X_test)\n",
        "predicted = np.argmax(logits, axis=1)\n",
        "print(classification_report(y_test, predicted))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1257, Val: 270, Test: 270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_18572\\3639948243.py:30: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  im = Image.fromarray(arr, mode=\"L\").resize((28, 28), Image.NEAREST)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos guardados en carpetas: digits_splits/train|val|test/<clase>/imagen.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import PIL.Image as Image\n",
        "# ========================\n",
        "# 2. Dividir en train, val, test\n",
        "# ========================\n",
        "# Primero: train vs resto\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "# Segundo: de ese resto, val vs test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.5, random_state=42, stratify=y_tmp\n",
        ")\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "# ========================\n",
        "# 3. Función para guardar imágenes\n",
        "# ========================\n",
        "def save_split(split_name, X_split, y_split, root=\"digits_splits\"):\n",
        "    split_dir = os.path.join(root, split_name)\n",
        "    for img, label in zip(X_split, y_split):\n",
        "        # Carpeta de la clase\n",
        "        class_dir = os.path.join(split_dir, str(label))\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        # Normalizar a 0–255 y convertir a uint8\n",
        "        arr = (255 * (img - img.min()) / (img.max() - img.min())).astype(np.uint8)\n",
        "\n",
        "        # Convertir a PIL y redimensionar a 28x28 (opcional, estilo MNIST)\n",
        "        im = Image.fromarray(arr, mode=\"L\").resize((28, 28), Image.NEAREST)\n",
        "\n",
        "        # Nombre de archivo único\n",
        "        fname = f\"{label}_{np.random.randint(1e9)}.png\"\n",
        "        im.save(os.path.join(class_dir, fname))\n",
        "\n",
        "# ========================\n",
        "# 4. Guardar cada split\n",
        "# ========================\n",
        "for split_name, Xs, ys in [\n",
        "    (\"train\", X_train, y_train),\n",
        "    (\"val\",   X_val,   y_val),\n",
        "    (\"test\",  X_test,  y_test),\n",
        "]:\n",
        "    save_split(split_name, Xs, ys)\n",
        "\n",
        "print(\"Datos guardados en carpetas: digits_splits/train|val|test/<clase>/imagen.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "VITcIIc0ua6d",
        "outputId": "32a6925c-ac63-4ded-8c33-efd26a75978d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Clase real: 6\n",
            "Clase predicha: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Elegir un índice de ejemplo del conjunto de prueba\n",
        "idx = 0  # Cambia a cualquier índice que quieras probar\n",
        "image = X_test[idx]  # Imagen aplanada\n",
        "label_true = y_test[idx]\n",
        "\n",
        "# Convertir a batch de 1 ejemplo\n",
        "image_batch = np.expand_dims(image, axis=0)  # shape (1, 64)\n",
        "\n",
        "# Pasar por el modelo\n",
        "logits = model.predict(image_batch)  # output logits\n",
        "predicted_class = np.argmax(logits, axis=1)[0]\n",
        "\n",
        "print(f'Clase real: {label_true}')\n",
        "print(f'Clase predicha: {predicted_class}')\n",
        "\n",
        "# Mostrar la imagen\n",
        "plt.imshow(image.reshape(8,8), cmap='gray')\n",
        "plt.title(f'True: {label_true}, Predicted: {predicted_class}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
